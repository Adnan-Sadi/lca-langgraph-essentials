{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27bd8e5-f539-4f58-822c-2db46990f4bd",
   "metadata": {},
   "source": [
    "# LangGraph Essentials V1: Build A Workflow\n",
    "<div style=\"display:flex; align-items:flex-start;\">\n",
    "  <img src=\"./Assets/EmailWorkflow.png\" width=\"600\" style=\"margin-right:15px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14584f8e-8ab3-402d-8fef-d88783f21b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Literal, TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40411549-4bb4-4668-9d3f-4a6ba994218a",
   "metadata": {},
   "source": [
    "## Step 1 Define state schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00af6aa-62de-4ed8-b927-69a1719aa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structure for email classification\n",
    "class EmailClassification(TypedDict):\n",
    "    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "    topic: str\n",
    "    summary: str\n",
    "\n",
    "# Define the state schema the application\n",
    "class EmailAgentState(TypedDict):\n",
    "    # Raw email data\n",
    "    email_content: str\n",
    "    sender_email: str\n",
    "    email_id: str\n",
    "\n",
    "    # Classification result\n",
    "    classification: EmailClassification | None\n",
    "\n",
    "    # Bug Tracking\n",
    "    ticket_id: str | None\n",
    "\n",
    "    # Raw search/API results\n",
    "    search_results: list[str] | None  # List of raw document chunks\n",
    "    customer_history: dict | None  # Raw customer data from CRM\n",
    "\n",
    "    # Generated content\n",
    "    draft_response: str | None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce75099-cb1b-420e-8c36-71e105fb249a",
   "metadata": {},
   "source": [
    "## Step 2: Define Nodes, Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89cc3cb2-d88b-49b9-b966-ab4514750599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n",
    "def read_email(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Extract and parse email content.\"\"\"\n",
    "    # In production, this would connect to your email service\n",
    "    # email_content is being passed in when the graph is invoked\n",
    "    pass\n",
    "    \n",
    "def classify_intent(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Use LLM to classify email intent and urgency, then route accordingly.\"\"\"\n",
    "\n",
    "    # Create structured LLM that returns EmailClassification dict\n",
    "    structured_llm = llm.with_structured_output(EmailClassification)\n",
    "\n",
    "    # Format the prompt on-demand, not stored in state\n",
    "    classification_prompt = f\"\"\"\n",
    "    Analyze this customer email and classify it:\n",
    "\n",
    "    Email: {state['email_content']}\n",
    "    From: {state['sender_email']}\n",
    "\n",
    "    Provide classification, including intent, urgency, topic, and summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get structured response directly as dict\n",
    "    classification = structured_llm.invoke(classification_prompt)\n",
    "\n",
    "    # Store classification as a single dict in state\n",
    "    return {\"classification\": classification}\n",
    "\n",
    "def search_documentation(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Search knowledge base for relevant information.\"\"\"\n",
    "\n",
    "    # Build search query from classification\n",
    "    classification = state.get('classification', {})\n",
    "    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n",
    "\n",
    "    try:\n",
    "        # Implement your search logic here\n",
    "        # Store raw search results, not formatted text\n",
    "        search_results = [\n",
    "            \"--Search_Result_1--\",\n",
    "            \"--Search_Result_2--\",\n",
    "            \"--Search_Result_3--\"\n",
    "        ]\n",
    "    except SearchAPIError as e:\n",
    "        # For recoverable search errors, store error and continue\n",
    "        search_results = [f\"Search temporarily unavailable: {str(e)}\"]\n",
    "\n",
    "    return {\"search_results\": search_results}  # Store raw results or error\n",
    "\n",
    "\n",
    "def bug_tracking(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Create or update bug tracking ticket.\"\"\"\n",
    "\n",
    "    # Create ticket in your bug tracking system\n",
    "    ticket_id = f\"BUG_{uuid.uuid4}\"  # Would be created via API\n",
    "\n",
    "    return {\n",
    "            \"ticket_id\": ticket_id,\n",
    "        }\n",
    "\n",
    "def write_response(state: EmailAgentState) -> Command[Literal[\"human_review\", \"send_reply\"]]:\n",
    "    \"\"\"Generate response using context and route based on quality.\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "    \n",
    "    # Format context from raw state data on-demand\n",
    "    context_sections = []\n",
    "\n",
    "    if state.get('search_results'):\n",
    "        # Format search results for the prompt\n",
    "        formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state['search_results']])\n",
    "        context_sections.append(f\"Relevant documentation:\\n{formatted_docs}\")\n",
    "\n",
    "    if state.get('customer_history'):\n",
    "        # Format customer data for the prompt\n",
    "        context_sections.append(f\"Customer tier: {state['customer_history'].get('tier', 'standard')}\")\n",
    "\n",
    "    # Build the prompt with formatted context\n",
    "    draft_prompt = f\"\"\"\n",
    "    Draft a response to this customer email:\n",
    "    {state['email_content']}\n",
    "\n",
    "    Email intent: {classification.get('intent', 'unknown')}\n",
    "    Urgency level: {classification.get('urgency', 'medium')}\n",
    "\n",
    "    {chr(10).join(context_sections)}\n",
    "\n",
    "    Guidelines:\n",
    "    - Be professional and helpful\n",
    "    - Address their specific concern\n",
    "    - Use the provided documentation when relevant\n",
    "    - Be brief\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(draft_prompt)\n",
    "    # Determine if human review is needed based on urgency and intent\n",
    "    needs_review = (\n",
    "        classification.get('urgency') in ['high', 'critical'] or\n",
    "        classification.get('intent') == 'complex'\n",
    "    )\n",
    "\n",
    "    # Route to the appropriate next node\n",
    "    if needs_review:\n",
    "        goto = \"human_review\"\n",
    "        print(\"Needs approval\")\n",
    "    else:\n",
    "        goto = \"send_reply\"\n",
    "\n",
    "    return Command(\n",
    "        update={\"draft_response\": response.content},  # Store only the raw response\n",
    "        goto=goto\n",
    "    )\n",
    "\n",
    "def human_review(state: EmailAgentState) -> Command[Literal[\"send_reply\", END]]:\n",
    "    \"\"\"Pause for human review using interrupt and route based on decision.\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "\n",
    "    # interrupt() must come first - any code before it will re-run on resume\n",
    "    human_decision = interrupt({\n",
    "        \"email_id\": state['email_id'],\n",
    "        \"original_email\": state['email_content'],\n",
    "        \"draft_response\": state.get('draft_response', \"\"),\n",
    "        \"urgency\": classification.get('urgency'),\n",
    "        \"intent\": classification.get('intent'),\n",
    "        \"action\": \"Please review and approve/edit this response\"\n",
    "    })\n",
    "\n",
    "    # Now process the human's decision\n",
    "    if human_decision.get(\"approved\"):\n",
    "        return Command(\n",
    "            update={\"draft_response\": human_decision.get(\"edited_response\", state['draft_response'])},\n",
    "            goto=\"send_reply\"\n",
    "        )\n",
    "    else:\n",
    "        # Rejection means human will handle directly\n",
    "        return Command(update={}, goto=END)\n",
    "\n",
    "def send_reply(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Send the email response.\"\"\"\n",
    "    # Integrate with email service\n",
    "    print(f\"Sending reply: {state['draft_response'][:60]}...\")\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44d6f1-8477-4da7-aea7-9c8b1da14897",
   "metadata": {},
   "source": [
    "## Step 3: Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92aacb00-eeaa-4618-9512-0fb0f7cd894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(EmailAgentState)\n",
    "\n",
    "# Add nodes \n",
    "workflow.add_node(\"read_email\", read_email)\n",
    "workflow.add_node(\"classify_intent\", classify_intent)\n",
    "workflow.add_node( \"search_documentation\", search_documentation )\n",
    "workflow.add_node(\"bug_tracking\", bug_tracking)\n",
    "workflow.add_node(\"write_response\", write_response)\n",
    "workflow.add_node(\"human_review\", human_review)\n",
    "workflow.add_node(\"send_reply\", send_reply)\n",
    "\n",
    "# Add edges (no edges for Command)\n",
    "workflow.add_edge(START, \"read_email\")\n",
    "workflow.add_edge(\"read_email\", \"classify_intent\")\n",
    "workflow.add_edge(\"classify_intent\", \"search_documentation\")\n",
    "workflow.add_edge(\"classify_intent\", \"bug_tracking\")\n",
    "workflow.add_edge(\"search_documentation\", \"write_response\")\n",
    "workflow.add_edge(\"bug_tracking\", \"write_response\")\n",
    "workflow.add_edge(\"send_reply\", END)\n",
    "\n",
    "# Compile with checkpointer for persistence\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec520c-4b55-49ce-8e1a-9b2d35d6f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0374b-d3fe-4663-8c8a-760b87d9964a",
   "metadata": {},
   "source": [
    "<div style=\"display:flex; align-items:flex-start;\">\n",
    "  <img src=\"./Assets/NunoGraph.png\" width=\"300\" style=\"margin-right:15px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "529d75a9-c1c6-4284-92b3-eea38281cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs approval\n"
     ]
    }
   ],
   "source": [
    "# Test with an urgent billing issue\n",
    "initial_state = {\n",
    "    \"email_content\": \"I was charged twice for my subscription! This is urgent!\",\n",
    "    \"sender_email\": \"customer@example.com\",\n",
    "    \"email_id\": \"email_123\",\n",
    "}\n",
    "\n",
    "# Run with a thread_id for persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"customer_123\"}}\n",
    "result = app.invoke(initial_state, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83f6c2d7-64bc-483b-98f5-f8471ffa5d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['email_content', 'sender_email', 'email_id', 'classification', 'ticket_id', 'search_results', 'draft_response', '__interrupt__'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6e3eee4-dc7e-4ea8-9c97-865144a62c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft ready for review: Subject: Re: Duplicate charge — we’ll resolve this ASAP\n",
      "\n",
      "Hi,...\n",
      "\n",
      "Sending reply: Subject: Re: Duplicate charge — we’ll resolve this ASAP\n",
      "\n",
      "Hi,...\n",
      "Email sent successfully!\n"
     ]
    }
   ],
   "source": [
    "# The graph will pause at human_review\n",
    "print(f\"Draft ready for review: {result['draft_response'][:60]}...\\n\")\n",
    "\n",
    "# When ready, provide human input to resume\n",
    "human_response = Command(\n",
    "    resume={\n",
    "        \"approved\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Resume execution\n",
    "final_result = app.invoke(human_response, config)\n",
    "print(\"Email sent successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9f88d93-4015-44e7-ad7d-e2397768c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_0: Needs approval\n",
      "email_1: Sending reply: Hello — thanks for reaching out.\n",
      "\n",
      "Could you tell me which pr...\n",
      "email_2: Sending reply: Hi,\n",
      "\n",
      "Thanks for reaching out. Which sale do you mean — the o...\n",
      "email_3: Needs approval\n",
      "email_4: Sending reply: Hi [Name],\n",
      "\n",
      "Thanks for checking — I can help with that. To c...\n"
     ]
    }
   ],
   "source": [
    "email_content = [\n",
    "    \"I was charged two times for my subscription! This is urgent!\",\n",
    "    \"I was wondering if this was available in blue?\",\n",
    "    \"Can you tell me how long the sale is on?\",\n",
    "    \"The tire won't stay on the car!\",\n",
    "    \"My subscription is going to end in a few months, what is the new rate?\"\n",
    "]\n",
    "needs_approval = []\n",
    "\n",
    "for i, content in enumerate(email_content): \n",
    "\n",
    "    initial_state = {\n",
    "        \"email_content\": content,\n",
    "        \"sender_email\": \"customer@example.com\",\n",
    "        \"email_id\": f\"email_{i}\",\n",
    "    }\n",
    "    print(f\"{initial_state['email_id']}: \", end=\"\")\n",
    "\n",
    "    thread_id = uuid.uuid4()\n",
    "    config =  {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    result = app.invoke(initial_state, config)\n",
    "    if \"__interrupt__\" in result.keys():\n",
    "        result['thread_id'] = thread_id\n",
    "        needs_approval.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd09600-a278-4b96-ac52-3ca77e2280ba",
   "metadata": {},
   "source": [
    ">LangSmith Trace - [Start-to-End](https://smith.langchain.com/public/3898d0d0-c934-4681-b325-7c4e1e88a826/r)  \n",
    ">LangSmith Trace - [Interrupt](https://smith.langchain.com/public/c23a3aed-cfa8-42aa-8f1e-78f58941aecd/r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d2427dd-947d-4add-9c35-55db30d33fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(needs_approval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63fbb702-12f9-44fd-9603-d9c57e3f656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_0: Sending reply: Hi — I’m sorry about the duplicate charge and I’ll get this ...\n",
      "email_3: Sending reply: Thanks — I’m very sorry and I understand how urgent this is....\n"
     ]
    }
   ],
   "source": [
    "for c_response in needs_approval:\n",
    "    \n",
    "    print(f\"{c_response['email_id']}: \", end=\"\")\n",
    "    human_response = Command( resume={\"approved\": True,} )\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": c_response[\"thread_id\"]}}\n",
    "    return_result = app.invoke(human_response, config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba15bd-9504-4797-af8f-b00aedd25ef7",
   "metadata": {},
   "source": [
    "[LangSmith Trace]( https://smith.langchain.com/public/36e1b840-69ca-4b45-b31f-c71a598e92d2/r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdebea4f-aedf-4a2f-8690-40dace733385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c7e0b-5508-4e68-9d2f-9c2360c0bdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806e8fa-d32e-4465-99bb-d50c5b394cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44186b8-f30b-4162-87f1-479648626d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545e497-5b01-4d80-95df-1e66b7498867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6daf6b0-cf10-4da3-9c3c-7f55fd95a486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453374ba-2ee2-4918-a24a-9ecdb3b2a021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9e232-c07b-4742-b4ae-c20f544d1d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1a7b7-e44c-4785-8249-9070ab6ad74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7caab-1a73-4ab7-9bc5-b360c937d7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63251555-1588-48d1-b774-190863fa82c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6451f-92f7-4f76-9995-c86601b4dad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06ce63-dbd0-4fdb-ae0c-3bf60fa3adee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a1232-886b-46a8-baae-b6613d401a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77148ed4-f3df-4b16-aae1-3815f02fd07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339a3a2-46f8-4e0d-8758-27bb02c671f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c033ea0-e4f4-4877-9d78-25a0c7f3c5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed54927-c09b-4a05-ab8e-8af2757326e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92916d0-a049-4f8f-96ae-69e72d3f59ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19dfc3a-ae59-46d9-9755-751717ff6ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9031cc-2dd1-4bcb-954e-5dc6c2428dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef414f49-0b2f-430d-902e-645b2793601b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244da78-2a18-4bda-a2db-28b3d8d5794d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5add9-207c-413b-a664-95b82c64d461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3125ee-aaf5-4256-acb2-d1e95aab9d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea172c1d-aa41-44fd-b69b-d9fe495747f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid.UUID"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo= uuid.uuid4()\n",
    "type(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "182ab82c-d3dd-4af2-b837-2d8a76d46da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c45a\n"
     ]
    }
   ],
   "source": [
    "print(foo.hex[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2a81f-6899-4fb7-8720-a4e73de03745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
